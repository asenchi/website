<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>complex-systems on asenchi.com</title>
    <link>/tags/complex-systems/</link>
    <description>Recent content in complex-systems on asenchi.com</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2022 Curt Micol &lt;asenchi@asenchi.com&gt;</copyright>
    <lastBuildDate>Tue, 23 Aug 2022 15:58:59 -0400</lastBuildDate><atom:link href="/tags/complex-systems/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Dealing with Catastrophe</title>
      <link>/posts/dealing-with-catastrophe/</link>
      <pubDate>Tue, 23 Aug 2022 15:58:59 -0400</pubDate>
      
      <guid>/posts/dealing-with-catastrophe/</guid>
      <description>6 Catastrophe is always just around the corner.
Complex systems possess potential for catastrophic failure. Human practitioners are nearly always in close physical and temporal proximity to these potential failures – disaster can occur at any time and in nearly any place. The potential for catastrophic outcome is a hallmark of complex systems. It is impossible to eliminate the potential for such catastrophic failure; the potential for such failure is always present by the system’s own nature.</description>
      <content>&lt;blockquote&gt;
&lt;p&gt;6 Catastrophe is always just around the corner.&lt;/p&gt;
&lt;p&gt;Complex systems possess potential for catastrophic failure. Human
practitioners are nearly always in close physical and temporal proximity to
these potential failures – disaster can occur at any time and in nearly any
place. The potential for catastrophic outcome is a hallmark of complex
systems. It is impossible to eliminate the potential for such catastrophic
failure; the potential for such failure is always present by the system’s own
nature.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The above quote is taken from Dr. Richard Cook&amp;rsquo;s seminal treatise, &lt;a href=&#34;https://how.complexsystems.fail&#34;&gt;&amp;ldquo;How Complex
Systems Fail&amp;rdquo;&lt;/a&gt;. The full paper is a must read for anyone working on
infrastructure and complex systems. However, this sixth point is of particular
importance to me because it has become a fundamental approach to every system I
have worked on since reading Dr. Cook&amp;rsquo;s paper nearly 12 years ago.&lt;/p&gt;
&lt;p&gt;My experience has shown this statement to be true. No matter how hard teams
worked to build reliable systems there was always an event that surprised us,
one that typically meant many people were going to lose many hours of their day
working to resolve the underlying incident.&lt;/p&gt;
&lt;p&gt;Approximately eight years ago I joined a new company that was in the middle of
a very large migration. The work had been in progress for 18 months. I came on
board about one month prior to the planned migration and helped organize a
timeline and rudimentary incident management process. Even with all of that
preparation we still experienced a catastrophic event that impacted a large
portion of our customers for greater than 24 hours.&lt;/p&gt;
&lt;p&gt;Perhaps the most surprising piece at the time was that our planning didn&amp;rsquo;t just
fall apart from a technical perspective, but we also saw results of a massive
communication breakdown that led to the confusion of our coworkers and our
customers. We had done the work to put together checklists with specific points
of communication to ensure we were all on the same page. We had assigned the
Incident Commander role to a rotation of people who understood the work and
they did a reasonable job updating situation reports. Yet when we finished the
internal post-mortem and shared it with our coworkers, many of them were
shocked to find out what had happened. There was an obvious problem here, one
that we had thought we had prepared for.&lt;/p&gt;
&lt;p&gt;Thankfully, the Director of our operations team at the time understood the
importance of finding a better way to deal with failure and gave me the space
to develop a method for our needs. I was deeply curious to find a better way
to engage our systems and support the teams across the company so that whenever
we faced a failure, whether planned or unplanned, my coworkers had the
information they needed to continue doing their job.&lt;/p&gt;
&lt;p&gt;At the time three key areas stuck out to me:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The burden of response: How can the process of incident response reduce the
stress on those actively addressing the incident?&lt;/li&gt;
&lt;li&gt;Clear and concise communication: How to inform all impacted parties whether
known or not?&lt;/li&gt;
&lt;li&gt;Non-technical Allies: How can the process of incident response support all
teams at all levels in the company that may be impacted by the particulars of
incident?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Any system that could solve these three issues would greatly improve our
ability to address not only catastrophic failures but any incident encountered.&lt;/p&gt;
&lt;p&gt;The work we are doing at &lt;a href=&#34;https://infrastellar.systems&#34;&gt;Infrastellar Systems&lt;/a&gt; is an extension of that
initial development of an incident management system. It is one that I have
continued to develop throughout the years. I&amp;rsquo;ve built up a lot of experience
integrating my system into large organizations. What I&amp;rsquo;ve learned from those
experiences I hope to put into tooling for companies to improve their
experience around catastrophic failures and more deeply understand their
production systems.&lt;/p&gt;
&lt;p&gt;Ultimately, the potential for failure exists in every system we develop. As
Dr. Cook says above, it is &amp;ldquo;always present by the system&amp;rsquo;s own nature.&amp;rdquo;
Incident management is an interface by which companies engage with their
systems in real-time. It isn&amp;rsquo;t the only one, but it may just be the most
important one.&lt;/p&gt;
</content>
    </item>
    
  </channel>
</rss>
